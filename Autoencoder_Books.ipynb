{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eapardox/Autoencoder_MovieLens1M/blob/main/Autoencoder_Books.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HFxNjT0MpI4I"
      },
      "outputs": [],
      "source": [
        "import abc\n",
        "import os\n",
        "from zipfile import ZipFile\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "from scipy.sparse import coo_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn import model_selection, metrics, preprocessing\n",
        "import torch.nn.parallel\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "from torch.autograd import Variable\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "requests.packages.urllib3.disable_warnings()\n",
        "import ssl\n",
        "try:\n",
        "    _create_unverified_https_context = ssl._create_unverified_context\n",
        "except AttributeError:\n",
        "    # Python heredado que no verifica los certificados HTTPS por defecto\n",
        "    pass\n",
        "else:\n",
        "    # Manejar el entorno de destino que no soporta la verificaci√≥n HTTPS\n",
        "    ssl._create_default_https_context = _create_unverified_https_context"
      ],
      "metadata": {
        "id": "t9MrPlxSH5dv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_columns', None)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "j9X6XmCJIOBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r-KX2GeJiRYJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "e40251c6-d73c-4cc0-981c-483382e5dcef"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   user_id  book_id  rating\n",
              "0     2487        1       4\n",
              "1    10146        1       5\n",
              "2    10246        1       4\n",
              "3    10335        1       4\n",
              "4    15494        1       5"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-eb2e2e9a-9f9b-46e4-a4ea-709612f73d15\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>book_id</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2487</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10146</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10246</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10335</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>15494</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eb2e2e9a-9f9b-46e4-a4ea-709612f73d15')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-eb2e2e9a-9f9b-46e4-a4ea-709612f73d15 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-eb2e2e9a-9f9b-46e4-a4ea-709612f73d15');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "df = pd.read_csv('ratings.csv', sep=';')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.user_id.unique().shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUZNN7-IACHv",
        "outputId": "f96bf5d7-7a54-48ca-f0a5-f8876751f67f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8902"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.book_id.unique().shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RPyhPTlAGPi",
        "outputId": "4ed9d729-1d79-47d2-884a-58ca73affa9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9999"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.rating.value_counts() # Distribuci√≥n del rating"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tj9mIduVAt_I",
        "outputId": "42d9b6f8-0d1c-4dc9-810b-dca103a82409"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4    84319\n",
              "5    69344\n",
              "3    58594\n",
              "2    15037\n",
              "1     4535\n",
              "Name: rating, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLCi8SzoANxC",
        "outputId": "a1343f7e-63fc-4b1a-e570-d6e164db2990"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "231829"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SK_4cXUQiojX",
        "outputId": "b6e30a7b-d851-42a5-c85b-c6b84fdc49c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 231829 entries, 0 to 231828\n",
            "Data columns (total 3 columns):\n",
            " #   Column   Non-Null Count   Dtype\n",
            "---  ------   --------------   -----\n",
            " 0   user_id  231829 non-null  int64\n",
            " 1   book_id  231829 non-null  int64\n",
            " 2   rating   231829 non-null  int64\n",
            "dtypes: int64(3)\n",
            "memory usage: 5.3 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PREPARACION DE DATOS DE PRUEBA Y ENTRENAMIENTO**"
      ],
      "metadata": {
        "id": "vbDW4cgDb7nY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XrOaFyt0izBj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7a30099-70c8-42ed-8a6c-1cb104275f3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hay 8902 usuarios, 9999 libros y 185463 observaciones en los datos de entrenamiento\n"
          ]
        }
      ],
      "source": [
        "# PREPARAMOS LOS DATOS EN ENTRENAMIENTO Y PRUEBA PARA SU ANALISIS\n",
        "# datos de entrenamiento (20%)\n",
        "train, test = train_test_split(df, test_size=0.2)\n",
        "\n",
        "# users, books and pares\n",
        "df_users = train.drop_duplicates(subset=['user_id'])[['user_id']]\n",
        "df_users['user'] = np.arange(len(df_users))\n",
        "df_items = train.drop_duplicates(subset=['book_id'])[['book_id']]\n",
        "df_items['item'] = np.arange(len(df_items))\n",
        "num_users = len(df_users)\n",
        "num_items = len(df_items)\n",
        "num_pairs = train.shape[0]\n",
        "print('Hay %s usuarios, %s libros y %s observaciones en los datos de entrenamiento' \\\n",
        "      %(num_users, num_items, num_pairs))\n",
        "\n",
        "# nuevos Ids renombrados\n",
        "train = pd.merge(train, df_users, on=['user_id'])\n",
        "train = pd.merge(train, df_items, on=['book_id'])\n",
        "\n",
        "# get x, y values\n",
        "x_train, y_train = train[['user', 'item']], train[['rating']].astype(float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BoVu5Qiei7ID",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b0aa2ff-4cf4-42dd-d97a-5c4f2d3ba6fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hay 8109 usuarios, 9857 libros y 46366 observaciones en los datos de prueba\n"
          ]
        }
      ],
      "source": [
        "# datos de prueba\n",
        "test = pd.merge(test, df_users, on=['user_id'], how='inner')\n",
        "test = pd.merge(test, df_items, on=['book_id'], how='inner')\n",
        "print('Hay %s usuarios, %s libros y %s observaciones en los datos de prueba' \\\n",
        "      %(len(test['user_id'].unique()), len(test['book_id'].unique()), test.shape[0]))\n",
        "\n",
        "# get x, y values\n",
        "x_test, y_test = test[['user', 'item']], test[['rating']].astype(float)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **FACTORIZACION MATRICIAL**"
      ],
      "metadata": {
        "id": "lFAncW9-bez5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V4D-PvxajC-x"
      },
      "outputs": [],
      "source": [
        "\n",
        "class MatrixFactorization(tf.keras.Model):\n",
        "    def __init__(self, num_users, num_items, embedding_size, **kwargs):\n",
        "        super(MatrixFactorization, self).__init__(**kwargs)\n",
        "        self.num_users = num_users\n",
        "        self.num_items = num_items\n",
        "        self.embedding_size = embedding_size\n",
        "        self.user_embedding = tf.keras.layers.Embedding(\n",
        "            self.num_users,\n",
        "            embedding_size,\n",
        "            #embeddings_initializer=\"he_normal\",\n",
        "            embeddings_regularizer=tf.keras.regularizers.l2(10),\n",
        "        )\n",
        "        self.user_bias = tf.keras.layers.Embedding(self.num_users, 1)\n",
        "        self.item_embedding = tf.keras.layers.Embedding(\n",
        "            self.num_items,\n",
        "            embedding_size,\n",
        "            #embeddings_initializer=\"he_normal\",\n",
        "            embeddings_regularizer=tf.keras.regularizers.l2(10),\n",
        "        )\n",
        "        self.item_bias = tf.keras.layers.Embedding(self.num_items, 1)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        user_vector = self.user_embedding(inputs[:, 0])\n",
        "        user_bias = self.user_bias(inputs[:, 0])\n",
        "        item_vector = self.item_embedding(inputs[:, 1])\n",
        "        item_bias = self.item_bias(inputs[:, 1])\n",
        "        dot_user_item = tf.tensordot(user_vector, item_vector, 2)\n",
        "        # A√±ade todos los componentes (incluido el sesgo)\n",
        "        output = dot_user_item + user_bias + item_bias\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C2wUCDAgjFrz"
      },
      "outputs": [],
      "source": [
        "# Params\n",
        "\n",
        "EMBEDDING_SIZE = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kdlx-PsXjJnk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa56ef7d-0d31-4fa5-8d4d-27e00cbd35de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "model = MatrixFactorization(num_users, num_items, EMBEDDING_SIZE)\n",
        "model.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
        "              optimizer=tf.keras.optimizers.Adam(lr=1e-3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6vP1eCvtjRN7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "393b8534-acb9-4aeb-829a-3dd689cf79ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "11592/11592 [==============================] - 51s 4ms/step - loss: 16.4669 - val_loss: 9.7679\n",
            "Epoch 2/30\n",
            "11592/11592 [==============================] - 48s 4ms/step - loss: 7.3628 - val_loss: 5.5787\n",
            "Epoch 3/30\n",
            "11592/11592 [==============================] - 52s 4ms/step - loss: 4.0650 - val_loss: 3.1925\n",
            "Epoch 4/30\n",
            "11592/11592 [==============================] - 47s 4ms/step - loss: 2.3444 - val_loss: 2.0181\n",
            "Epoch 5/30\n",
            "11592/11592 [==============================] - 52s 4ms/step - loss: 1.5323 - val_loss: 1.4563\n",
            "Epoch 6/30\n",
            "11592/11592 [==============================] - 49s 4ms/step - loss: 1.1438 - val_loss: 1.1757\n",
            "Epoch 7/30\n",
            "11592/11592 [==============================] - 47s 4ms/step - loss: 0.9458 - val_loss: 1.0244\n",
            "Epoch 8/30\n",
            "11592/11592 [==============================] - 47s 4ms/step - loss: 0.8367 - val_loss: 0.9372\n",
            "Epoch 9/30\n",
            "11592/11592 [==============================] - 52s 5ms/step - loss: 0.7722 - val_loss: 0.8835\n",
            "Epoch 10/30\n",
            "11592/11592 [==============================] - 47s 4ms/step - loss: 0.7315 - val_loss: 0.8484\n",
            "Epoch 11/30\n",
            "11592/11592 [==============================] - 47s 4ms/step - loss: 0.7046 - val_loss: 0.8236\n",
            "Epoch 12/30\n",
            "11592/11592 [==============================] - 52s 4ms/step - loss: 0.6856 - val_loss: 0.8062\n",
            "Epoch 13/30\n",
            "11592/11592 [==============================] - 52s 4ms/step - loss: 0.6721 - val_loss: 0.7932\n",
            "Epoch 14/30\n",
            "11592/11592 [==============================] - 47s 4ms/step - loss: 0.6619 - val_loss: 0.7836\n",
            "Epoch 15/30\n",
            "11592/11592 [==============================] - 51s 4ms/step - loss: 0.6540 - val_loss: 0.7756\n",
            "Epoch 16/30\n",
            "11592/11592 [==============================] - 48s 4ms/step - loss: 0.6478 - val_loss: 0.7691\n",
            "Epoch 17/30\n",
            "11592/11592 [==============================] - 47s 4ms/step - loss: 0.6429 - val_loss: 0.7640\n",
            "Epoch 18/30\n",
            "11592/11592 [==============================] - 51s 4ms/step - loss: 0.6389 - val_loss: 0.7597\n",
            "Epoch 19/30\n",
            "11592/11592 [==============================] - 48s 4ms/step - loss: 0.6358 - val_loss: 0.7563\n",
            "Epoch 20/30\n",
            "11592/11592 [==============================] - 47s 4ms/step - loss: 0.6331 - val_loss: 0.7538\n",
            "Epoch 21/30\n",
            "11592/11592 [==============================] - 47s 4ms/step - loss: 0.6310 - val_loss: 0.7517\n",
            "Epoch 22/30\n",
            "11592/11592 [==============================] - 47s 4ms/step - loss: 0.6293 - val_loss: 0.7497\n",
            "Epoch 23/30\n",
            "11592/11592 [==============================] - 53s 5ms/step - loss: 0.6279 - val_loss: 0.7481\n",
            "Epoch 24/30\n",
            "11592/11592 [==============================] - 46s 4ms/step - loss: 0.6267 - val_loss: 0.7473\n",
            "Epoch 25/30\n",
            "11592/11592 [==============================] - 46s 4ms/step - loss: 0.6257 - val_loss: 0.7458\n",
            "Epoch 26/30\n",
            "11592/11592 [==============================] - 48s 4ms/step - loss: 0.6249 - val_loss: 0.7448\n",
            "Epoch 27/30\n",
            "11592/11592 [==============================] - 52s 4ms/step - loss: 0.6242 - val_loss: 0.7437\n",
            "Epoch 28/30\n",
            "11592/11592 [==============================] - 47s 4ms/step - loss: 0.6236 - val_loss: 0.7434\n",
            "Epoch 29/30\n",
            "11592/11592 [==============================] - 47s 4ms/step - loss: 0.6231 - val_loss: 0.7432\n",
            "Epoch 30/30\n",
            "11592/11592 [==============================] - 52s 5ms/step - loss: 0.6228 - val_loss: 0.7427\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    batch_size=16, # rendimiento para la GPU\n",
        "    epochs=30,\n",
        "    verbose=1,\n",
        "    validation_data=(x_test, y_test)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lw-6O07JoLyb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "ee34dd39-d862-49d6-9167-3e1c4f9f8393"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Plot p√©rdida de entrenamiento\n",
        "\n",
        "plt.plot(history.history[\"loss\"])\n",
        "plt.plot(history.history[\"val_loss\"], '--')\n",
        "plt.title(\"model loss\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.legend([\"train\", \"test\"], loc=\"upper left\")\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3mUdhCC9oT16"
      },
      "outputs": [],
      "source": [
        "def recommend(user_id, train, test, df_items, df_aux):\n",
        "  movies_watched_by_user = train[train.user == user_id]\n",
        "\n",
        "  df_items_aux = df_items[['item']]\n",
        "  df_items_aux['user'] = user_id\n",
        "  movies_not_watched = pd.merge(df_items_aux, movies_watched_by_user, on=['user', 'item'], how='left')\n",
        "  movies_not_watched = movies_not_watched[movies_not_watched.rating.isnull()][['user', 'item']]\n",
        "\n",
        "  ratings = model.predict(movies_not_watched).flatten()\n",
        "  movies_not_watched['predicted_rating'] = ratings\n",
        "  top_ratings_items = movies_not_watched.sort_values(by='predicted_rating', ascending=False)\n",
        "\n",
        "  print(\"Mostrar recomendaciones para el usuario: {}\".format(user_id))\n",
        "  print(\"====\" * 9)\n",
        "  print(\"Pel√≠culas con altas valoraciones de los usuarios\")\n",
        "  print(\"----\" * 8)\n",
        "\n",
        "  movies_watched_by_user = pd.merge(movies_watched_by_user, df_aux, on=['item_id'])\n",
        "  top_movies_user = movies_watched_by_user.sort_values(by='rating', ascending=False)[['user', 'item', 'rating', 'movie_title']]\n",
        "  print(top_movies_user.head(20))\n",
        "\n",
        "  print(\"====\" * 9)\n",
        "  print(\"Calificaciones de las pel√≠culas vistas en los datos de prueba\")\n",
        "  print(\"----\" * 8)\n",
        "  movies_watched_by_user_test = test[test.user == user_id]\n",
        "  movies_watched_by_user_test = pd.merge(movies_watched_by_user_test, df_aux, on=['item_id'])\n",
        "  movies_watched_by_user_test = pd.merge(movies_watched_by_user_test, movies_not_watched, on=['user', 'item'])\n",
        "  movies_user_test = movies_watched_by_user_test.sort_values(by='rating', ascending=False)[['user', 'item', 'rating', 'predicted_rating', 'movie_title']]\n",
        "  print(movies_user_test.head(20))\n",
        "\n",
        "  print(\"----\" * 8)\n",
        "  print(\"Top 10 recomendaciones de pel√≠culas\")\n",
        "  print(\"----\" * 8)\n",
        "  top_movies_recommended = pd.merge(top_ratings_items, df_items, on=['item'])\n",
        "  top_movies_recommended = pd.merge(top_movies_recommended, df_aux, on=['item_id'])\n",
        "  print(top_movies_recommended[['item', 'predicted_rating', 'movie_title']].head(20))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ooorThnoa9H"
      },
      "outputs": [],
      "source": [
        "# Mostrar las 10 mejores recomendaciones de pel√≠culas a un usuario\n",
        "\n",
        "user_id = test.user.sample(1).iloc[0]\n",
        "recommend(user_id, train, test, df_items, df_item_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **AUTOENCODER**"
      ],
      "metadata": {
        "id": "aKOyKE--bvRg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ee_Ed40GomJE"
      },
      "outputs": [],
      "source": [
        "# ****************---------------******************-----------------------#\n",
        "# ****************---------------******************-----------------------#\n",
        "# MODELO DE FC DE DNN BASADO EN AUTOENCODERS (AutoRec)\n",
        "class AutoRec(tf.keras.Model):\n",
        "  def __init__(self, num_hidden, num_users, dropout=0.05, reg_enc=1e-2, reg_dec=1e-2):\n",
        "    super(AutoRec, self).__init__()\n",
        "    self.encoder = tf.keras.layers.Dense(num_hidden, activation='sigmoid',\n",
        "                                         use_bias=True,\n",
        "                                         kernel_regularizer=tf.keras.regularizers.l2(reg_enc))\n",
        "    self.decoder = tf.keras.layers.Dense(num_users, use_bias=True,\n",
        "                                         kernel_regularizer=tf.keras.regularizers.l2(reg_dec))\n",
        "    self.dropout = tf.keras.layers.Dropout(dropout)\n",
        "\n",
        "  def call(self, input, training=None):\n",
        "    hidden = self.dropout(self.encoder(input))\n",
        "    pred = self.decoder(hidden)\n",
        "    return pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZbvMDPjpCZS"
      },
      "outputs": [],
      "source": [
        "# Sistema m√©trico RMSE (FUNCION DE PERDIDA)\n",
        "\n",
        "def autorec_rmse(y_true, y_pred):\n",
        "  y_mask = tf.math.sign(y_true)\n",
        "  squared_difference = tf.square(y_true - y_pred * y_mask)\n",
        "  return tf.sqrt(tf.reduce_sum(squared_difference, axis=-1) / tf.math.maximum(tf.reduce_sum(y_mask, axis=-1), 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kPnwz73spF-O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "outputId": "0b4b6668-83b6-4e4a-b255-672cc5577888"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   user                                               item  \\\n",
              "0     0  [0, 3760, 4400, 1350, 8545, 8672, 2222, 5598, ...   \n",
              "1     1  [1, 139, 7121, 6197, 3152, 3410, 2961, 2363, 1...   \n",
              "2     2  [2, 2200, 2405, 4334, 5373, 5376, 2903, 1352, ...   \n",
              "3     3  [3, 4427, 787, 5244, 4013, 264, 3846, 1982, 34...   \n",
              "4     4  [584, 4, 546, 1875, 2282, 2293, 3419, 3897, 45...   \n",
              "\n",
              "                                              rating  \\\n",
              "0  [5, 3, 5, 5, 5, 4, 3, 5, 5, 3, 5, 4, 4, 4, 4, ...   \n",
              "1  [3, 3, 5, 5, 3, 3, 4, 3, 1, 4, 3, 5, 3, 5, 5, ...   \n",
              "2  [4, 3, 4, 4, 3, 4, 4, 4, 3, 5, 4, 3, 4, 4, 5, ...   \n",
              "3  [4, 4, 5, 5, 4, 3, 4, 3, 4, 4, 5, 3, 4, 3, 3, ...   \n",
              "4  [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...   \n",
              "\n",
              "                                               input  \n",
              "0  [5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
              "1  [0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
              "2  [0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
              "3  [0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
              "4  [0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ebff160f-d303-4f14-b9b5-2c8c63a4186d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user</th>\n",
              "      <th>item</th>\n",
              "      <th>rating</th>\n",
              "      <th>input</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>[0, 3760, 4400, 1350, 8545, 8672, 2222, 5598, ...</td>\n",
              "      <td>[5, 3, 5, 5, 5, 4, 3, 5, 5, 3, 5, 4, 4, 4, 4, ...</td>\n",
              "      <td>[5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>[1, 139, 7121, 6197, 3152, 3410, 2961, 2363, 1...</td>\n",
              "      <td>[3, 3, 5, 5, 3, 3, 4, 3, 1, 4, 3, 5, 3, 5, 5, ...</td>\n",
              "      <td>[0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>[2, 2200, 2405, 4334, 5373, 5376, 2903, 1352, ...</td>\n",
              "      <td>[4, 3, 4, 4, 3, 4, 4, 4, 3, 5, 4, 3, 4, 4, 5, ...</td>\n",
              "      <td>[0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>[3, 4427, 787, 5244, 4013, 264, 3846, 1982, 34...</td>\n",
              "      <td>[4, 4, 5, 5, 4, 3, 4, 3, 4, 4, 5, 3, 4, 3, 3, ...</td>\n",
              "      <td>[0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>[584, 4, 546, 1875, 2282, 2293, 3419, 3897, 45...</td>\n",
              "      <td>[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
              "      <td>[0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ebff160f-d303-4f14-b9b5-2c8c63a4186d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ebff160f-d303-4f14-b9b5-2c8c63a4186d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ebff160f-d303-4f14-b9b5-2c8c63a4186d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# data\n",
        "\n",
        "ae_data_train = train.groupby('user').agg({'item': list, 'rating': list}).reset_index()\n",
        "ae_data_train['input'] = ae_data_train.apply(lambda x: np.squeeze(coo_matrix((x[2], (np.zeros_like(x[1]), x[1])),\n",
        "                                                                  shape=(1, num_items)).toarray()),\n",
        "                                             axis=1)\n",
        "ae_data_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Il3ElIGwpM_Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06ec86e1-9d3f-466b-f7b1-9fe9f2dbff6a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 3., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 4., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "x_train_autorec = ae_data_train.values[:, 3]\n",
        "x_train_autorec = np.stack(x_train_autorec).astype(float)\n",
        "x_train_autorec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Y3BS8DipPDP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9aaa07a8-e185-4810-e2d3-06eb2b43111e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# test - validaci√≥n\n",
        "ae_data_test = test.groupby('user').agg({'item': list, 'rating': list}).reset_index()\n",
        "ae_data_test['input'] = ae_data_test.apply(lambda x: np.squeeze(coo_matrix((x[2], (np.zeros_like(x[1]), x[1])),\n",
        "                                                                shape=(1, num_items)).toarray()),\n",
        "                                           axis=1)\n",
        "\n",
        "ae_data_test_aux = pd.merge(ae_data_train, ae_data_test, on=['user'], how='inner')\n",
        "x_test_autorec = np.stack(ae_data_test_aux.values[:, -1]).astype(float)\n",
        "x_test_autorec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C-83p__4pTpb"
      },
      "outputs": [],
      "source": [
        "# par√°metros VARIAR VALORES\n",
        "NUM_HIDDEN = 300\n",
        "DROPOUT = 0.05\n",
        "REG_ENC = 1e-2\n",
        "REG_DEC = 1e-2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RPP_aH7kpX81",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f313ef4a-eecb-4592-fed3-ef71c9fb36a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "model = AutoRec(NUM_HIDDEN, num_items, DROPOUT, REG_ENC, REG_DEC)\n",
        "model.compile(loss=autorec_rmse,\n",
        "              optimizer=tf.keras.optimizers.Adam(lr=1e-3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O0ePsMjMpoUx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b89c28db-7761-449e-a926-3e15b93f15a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "70/70 [==============================] - 2s 26ms/step - loss: 5.0495 - val_loss: 3.7536\n",
            "Epoch 2/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 3.7536 - val_loss: 3.7128\n",
            "Epoch 3/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 3.7196 - val_loss: 3.6739\n",
            "Epoch 4/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 3.6830 - val_loss: 3.6444\n",
            "Epoch 5/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 3.6460 - val_loss: 3.6039\n",
            "Epoch 6/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 3.6105 - val_loss: 3.5638\n",
            "Epoch 7/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 3.5717 - val_loss: 3.5256\n",
            "Epoch 8/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 3.5338 - val_loss: 3.4898\n",
            "Epoch 9/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 3.4954 - val_loss: 3.4452\n",
            "Epoch 10/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 3.4573 - val_loss: 3.4090\n",
            "Epoch 11/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 3.4191 - val_loss: 3.3726\n",
            "Epoch 12/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 3.3798 - val_loss: 3.3328\n",
            "Epoch 13/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 3.3453 - val_loss: 3.3046\n",
            "Epoch 14/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 3.3107 - val_loss: 3.2677\n",
            "Epoch 15/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 3.2705 - val_loss: 3.2229\n",
            "Epoch 16/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 3.2345 - val_loss: 3.1849\n",
            "Epoch 17/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 3.2000 - val_loss: 3.1550\n",
            "Epoch 18/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 3.1655 - val_loss: 3.1176\n",
            "Epoch 19/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 3.1325 - val_loss: 3.0825\n",
            "Epoch 20/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 3.0958 - val_loss: 3.0529\n",
            "Epoch 21/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 3.0653 - val_loss: 3.0174\n",
            "Epoch 22/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 3.0326 - val_loss: 2.9855\n",
            "Epoch 23/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 3.0009 - val_loss: 2.9515\n",
            "Epoch 24/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 2.9716 - val_loss: 2.9279\n",
            "Epoch 25/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 2.9410 - val_loss: 2.8951\n",
            "Epoch 26/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 2.9100 - val_loss: 2.8702\n",
            "Epoch 27/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 2.8813 - val_loss: 2.8405\n",
            "Epoch 28/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 2.8536 - val_loss: 2.8002\n",
            "Epoch 29/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 2.8263 - val_loss: 2.7743\n",
            "Epoch 30/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 2.7989 - val_loss: 2.7548\n",
            "Epoch 31/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 2.7703 - val_loss: 2.7129\n",
            "Epoch 32/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 2.7445 - val_loss: 2.6946\n",
            "Epoch 33/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 2.7177 - val_loss: 2.6632\n",
            "Epoch 34/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 2.6915 - val_loss: 2.6469\n",
            "Epoch 35/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 2.6667 - val_loss: 2.6224\n",
            "Epoch 36/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 2.6426 - val_loss: 2.5897\n",
            "Epoch 37/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 2.6180 - val_loss: 2.5755\n",
            "Epoch 38/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 2.5945 - val_loss: 2.5478\n",
            "Epoch 39/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 2.5696 - val_loss: 2.5159\n",
            "Epoch 40/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 2.5481 - val_loss: 2.4976\n",
            "Epoch 41/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 2.5240 - val_loss: 2.4722\n",
            "Epoch 42/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 2.4971 - val_loss: 2.4575\n",
            "Epoch 43/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 2.4789 - val_loss: 2.4363\n",
            "Epoch 44/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 2.4578 - val_loss: 2.4041\n",
            "Epoch 45/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 2.4365 - val_loss: 2.3935\n",
            "Epoch 46/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 2.4126 - val_loss: 2.3652\n",
            "Epoch 47/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 2.3928 - val_loss: 2.3546\n",
            "Epoch 48/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 2.3754 - val_loss: 2.3241\n",
            "Epoch 49/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 2.3529 - val_loss: 2.3056\n",
            "Epoch 50/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 2.3321 - val_loss: 2.2834\n",
            "Epoch 51/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 2.3131 - val_loss: 2.2641\n",
            "Epoch 52/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 2.2930 - val_loss: 2.2476\n",
            "Epoch 53/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 2.2733 - val_loss: 2.2248\n",
            "Epoch 54/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 2.2582 - val_loss: 2.2085\n",
            "Epoch 55/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 2.2365 - val_loss: 2.1872\n",
            "Epoch 56/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 2.2188 - val_loss: 2.1767\n",
            "Epoch 57/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 2.2017 - val_loss: 2.1521\n",
            "Epoch 58/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 2.1848 - val_loss: 2.1354\n",
            "Epoch 59/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 2.1633 - val_loss: 2.1164\n",
            "Epoch 60/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 2.1476 - val_loss: 2.0997\n",
            "Epoch 61/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 2.1302 - val_loss: 2.0789\n",
            "Epoch 62/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 2.1140 - val_loss: 2.0650\n",
            "Epoch 63/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 2.0955 - val_loss: 2.0501\n",
            "Epoch 64/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 2.0802 - val_loss: 2.0322\n",
            "Epoch 65/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 2.0634 - val_loss: 2.0133\n",
            "Epoch 66/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 2.0470 - val_loss: 2.0012\n",
            "Epoch 67/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 2.0325 - val_loss: 1.9796\n",
            "Epoch 68/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 2.0181 - val_loss: 1.9719\n",
            "Epoch 69/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 2.0035 - val_loss: 1.9577\n",
            "Epoch 70/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 1.9869 - val_loss: 1.9399\n",
            "Epoch 71/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.9671 - val_loss: 1.9202\n",
            "Epoch 72/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.9558 - val_loss: 1.9057\n",
            "Epoch 73/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.9393 - val_loss: 1.8883\n",
            "Epoch 74/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.9278 - val_loss: 1.8756\n",
            "Epoch 75/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.9157 - val_loss: 1.8594\n",
            "Epoch 76/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.8989 - val_loss: 1.8508\n",
            "Epoch 77/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.8876 - val_loss: 1.8378\n",
            "Epoch 78/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.8723 - val_loss: 1.8274\n",
            "Epoch 79/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.8589 - val_loss: 1.8050\n",
            "Epoch 80/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.8429 - val_loss: 1.7999\n",
            "Epoch 81/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.8335 - val_loss: 1.7814\n",
            "Epoch 82/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.8203 - val_loss: 1.7705\n",
            "Epoch 83/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.8064 - val_loss: 1.7487\n",
            "Epoch 84/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.7931 - val_loss: 1.7462\n",
            "Epoch 85/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.7831 - val_loss: 1.7356\n",
            "Epoch 86/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.7717 - val_loss: 1.7199\n",
            "Epoch 87/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.7593 - val_loss: 1.7087\n",
            "Epoch 88/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.7465 - val_loss: 1.7022\n",
            "Epoch 89/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.7345 - val_loss: 1.6854\n",
            "Epoch 90/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.7225 - val_loss: 1.6817\n",
            "Epoch 91/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.7127 - val_loss: 1.6764\n",
            "Epoch 92/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.7020 - val_loss: 1.6512\n",
            "Epoch 93/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.6899 - val_loss: 1.6427\n",
            "Epoch 94/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.6787 - val_loss: 1.6291\n",
            "Epoch 95/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.6693 - val_loss: 1.6209\n",
            "Epoch 96/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.6578 - val_loss: 1.6077\n",
            "Epoch 97/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.6482 - val_loss: 1.5976\n",
            "Epoch 98/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.6384 - val_loss: 1.5886\n",
            "Epoch 99/1000\n",
            "70/70 [==============================] - 1s 17ms/step - loss: 1.6291 - val_loss: 1.5799\n",
            "Epoch 100/1000\n",
            "70/70 [==============================] - 1s 16ms/step - loss: 1.6208 - val_loss: 1.5754\n",
            "Epoch 101/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.6108 - val_loss: 1.5628\n",
            "Epoch 102/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.6019 - val_loss: 1.5519\n",
            "Epoch 103/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.5919 - val_loss: 1.5472\n",
            "Epoch 104/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.5817 - val_loss: 1.5407\n",
            "Epoch 105/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.5740 - val_loss: 1.5328\n",
            "Epoch 106/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.5635 - val_loss: 1.5163\n",
            "Epoch 107/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.5568 - val_loss: 1.5087\n",
            "Epoch 108/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.5497 - val_loss: 1.5004\n",
            "Epoch 109/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.5401 - val_loss: 1.4867\n",
            "Epoch 110/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.5306 - val_loss: 1.4879\n",
            "Epoch 111/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.5218 - val_loss: 1.4799\n",
            "Epoch 112/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 1.5164 - val_loss: 1.4673\n",
            "Epoch 113/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.5075 - val_loss: 1.4620\n",
            "Epoch 114/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.4993 - val_loss: 1.4592\n",
            "Epoch 115/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.4924 - val_loss: 1.4328\n",
            "Epoch 116/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.4845 - val_loss: 1.4432\n",
            "Epoch 117/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.4746 - val_loss: 1.4315\n",
            "Epoch 118/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 1.4708 - val_loss: 1.4223\n",
            "Epoch 119/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 1.4627 - val_loss: 1.4207\n",
            "Epoch 120/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 1.4584 - val_loss: 1.4084\n",
            "Epoch 121/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.4487 - val_loss: 1.4020\n",
            "Epoch 122/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.4444 - val_loss: 1.4013\n",
            "Epoch 123/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.4367 - val_loss: 1.3962\n",
            "Epoch 124/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 1.4302 - val_loss: 1.3863\n",
            "Epoch 125/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 1.4251 - val_loss: 1.3871\n",
            "Epoch 126/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.4155 - val_loss: 1.3723\n",
            "Epoch 127/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.4130 - val_loss: 1.3640\n",
            "Epoch 128/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.4044 - val_loss: 1.3576\n",
            "Epoch 129/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 1.3991 - val_loss: 1.3564\n",
            "Epoch 130/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.3925 - val_loss: 1.3494\n",
            "Epoch 131/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 1.3865 - val_loss: 1.3473\n",
            "Epoch 132/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 1.3838 - val_loss: 1.3403\n",
            "Epoch 133/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.3769 - val_loss: 1.3295\n",
            "Epoch 134/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.3737 - val_loss: 1.3281\n",
            "Epoch 135/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 1.3668 - val_loss: 1.3222\n",
            "Epoch 136/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 1.3601 - val_loss: 1.3185\n",
            "Epoch 137/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 1.3552 - val_loss: 1.3195\n",
            "Epoch 138/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 1.3517 - val_loss: 1.3088\n",
            "Epoch 139/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 1.3475 - val_loss: 1.3068\n",
            "Epoch 140/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 1.3388 - val_loss: 1.2995\n",
            "Epoch 141/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.3366 - val_loss: 1.2958\n",
            "Epoch 142/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 1.3326 - val_loss: 1.2912\n",
            "Epoch 143/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 1.3275 - val_loss: 1.2851\n",
            "Epoch 144/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.3192 - val_loss: 1.2851\n",
            "Epoch 145/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 1.3193 - val_loss: 1.2805\n",
            "Epoch 146/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 1.3132 - val_loss: 1.2749\n",
            "Epoch 147/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 1.3088 - val_loss: 1.2724\n",
            "Epoch 148/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.3064 - val_loss: 1.2568\n",
            "Epoch 149/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.3019 - val_loss: 1.2567\n",
            "Epoch 150/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.2959 - val_loss: 1.2605\n",
            "Epoch 151/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.2923 - val_loss: 1.2533\n",
            "Epoch 152/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.2879 - val_loss: 1.2578\n",
            "Epoch 153/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.2845 - val_loss: 1.2465\n",
            "Epoch 154/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 1.2824 - val_loss: 1.2450\n",
            "Epoch 155/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 1.2763 - val_loss: 1.2375\n",
            "Epoch 156/1000\n",
            "70/70 [==============================] - 1s 18ms/step - loss: 1.2751 - val_loss: 1.2337\n",
            "Epoch 157/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.2711 - val_loss: 1.2280\n",
            "Epoch 158/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 1.2675 - val_loss: 1.2288\n",
            "Epoch 159/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.2658 - val_loss: 1.2262\n",
            "Epoch 160/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 1.2586 - val_loss: 1.2124\n",
            "Epoch 161/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 1.2561 - val_loss: 1.2225\n",
            "Epoch 162/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 1.2533 - val_loss: 1.2178\n",
            "Epoch 163/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 1.2496 - val_loss: 1.2084\n",
            "Epoch 164/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 1.2464 - val_loss: 1.2171\n",
            "Epoch 165/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.2448 - val_loss: 1.1980\n",
            "Epoch 166/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.2415 - val_loss: 1.1982\n",
            "Epoch 167/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.2388 - val_loss: 1.2024\n",
            "Epoch 168/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 1.2336 - val_loss: 1.1994\n",
            "Epoch 169/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 1.2344 - val_loss: 1.1913\n",
            "Epoch 170/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 1.2282 - val_loss: 1.1889\n",
            "Epoch 171/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 1.2256 - val_loss: 1.1882\n",
            "Epoch 172/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.2244 - val_loss: 1.1854\n",
            "Epoch 173/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 1.2197 - val_loss: 1.1829\n",
            "Epoch 174/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 1.2177 - val_loss: 1.1860\n",
            "Epoch 175/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 1.2176 - val_loss: 1.1740\n",
            "Epoch 176/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.2087 - val_loss: 1.1831\n",
            "Epoch 177/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 1.2100 - val_loss: 1.1737\n",
            "Epoch 178/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 1.2080 - val_loss: 1.1665\n",
            "Epoch 179/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.2034 - val_loss: 1.1734\n",
            "Epoch 180/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.2010 - val_loss: 1.1674\n",
            "Epoch 181/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.1992 - val_loss: 1.1663\n",
            "Epoch 182/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.1993 - val_loss: 1.1615\n",
            "Epoch 183/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.1982 - val_loss: 1.1608\n",
            "Epoch 184/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 1.1909 - val_loss: 1.1498\n",
            "Epoch 185/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.1930 - val_loss: 1.1578\n",
            "Epoch 186/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.1902 - val_loss: 1.1570\n",
            "Epoch 187/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 1.1866 - val_loss: 1.1531\n",
            "Epoch 188/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.1834 - val_loss: 1.1555\n",
            "Epoch 189/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.1824 - val_loss: 1.1515\n",
            "Epoch 190/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.1780 - val_loss: 1.1541\n",
            "Epoch 191/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.1798 - val_loss: 1.1453\n",
            "Epoch 192/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 1.1766 - val_loss: 1.1453\n",
            "Epoch 193/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 1.1739 - val_loss: 1.1404\n",
            "Epoch 194/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.1719 - val_loss: 1.1429\n",
            "Epoch 195/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 1.1685 - val_loss: 1.1397\n",
            "Epoch 196/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.1666 - val_loss: 1.1427\n",
            "Epoch 197/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 1.1641 - val_loss: 1.1360\n",
            "Epoch 198/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 1.1641 - val_loss: 1.1371\n",
            "Epoch 199/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.1611 - val_loss: 1.1251\n",
            "Epoch 200/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 1.1598 - val_loss: 1.1282\n",
            "Epoch 201/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.1587 - val_loss: 1.1307\n",
            "Epoch 202/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.1528 - val_loss: 1.1215\n",
            "Epoch 203/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.1509 - val_loss: 1.1193\n",
            "Epoch 204/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.1526 - val_loss: 1.1155\n",
            "Epoch 205/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 1.1492 - val_loss: 1.1220\n",
            "Epoch 206/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.1455 - val_loss: 1.1124\n",
            "Epoch 207/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.1418 - val_loss: 1.1097\n",
            "Epoch 208/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.1408 - val_loss: 1.1091\n",
            "Epoch 209/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.1365 - val_loss: 1.1024\n",
            "Epoch 210/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.1348 - val_loss: 1.1016\n",
            "Epoch 211/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 1.1293 - val_loss: 1.1028\n",
            "Epoch 212/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 1.1286 - val_loss: 1.1013\n",
            "Epoch 213/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 1.1268 - val_loss: 1.1016\n",
            "Epoch 214/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 1.1218 - val_loss: 1.0917\n",
            "Epoch 215/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 1.1180 - val_loss: 1.0940\n",
            "Epoch 216/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 1.1161 - val_loss: 1.0939\n",
            "Epoch 217/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.1135 - val_loss: 1.0902\n",
            "Epoch 218/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.1065 - val_loss: 1.0846\n",
            "Epoch 219/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.1038 - val_loss: 1.0768\n",
            "Epoch 220/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.1001 - val_loss: 1.0769\n",
            "Epoch 221/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 1.0936 - val_loss: 1.0727\n",
            "Epoch 222/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.0934 - val_loss: 1.0638\n",
            "Epoch 223/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.0877 - val_loss: 1.0691\n",
            "Epoch 224/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.0857 - val_loss: 1.0603\n",
            "Epoch 225/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.0803 - val_loss: 1.0595\n",
            "Epoch 226/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.0782 - val_loss: 1.0510\n",
            "Epoch 227/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.0744 - val_loss: 1.0571\n",
            "Epoch 228/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.0708 - val_loss: 1.0563\n",
            "Epoch 229/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 1.0682 - val_loss: 1.0515\n",
            "Epoch 230/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 1.0648 - val_loss: 1.0468\n",
            "Epoch 231/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.0613 - val_loss: 1.0435\n",
            "Epoch 232/1000\n",
            "70/70 [==============================] - 1s 18ms/step - loss: 1.0588 - val_loss: 1.0426\n",
            "Epoch 233/1000\n",
            "70/70 [==============================] - 1s 20ms/step - loss: 1.0567 - val_loss: 1.0386\n",
            "Epoch 234/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.0534 - val_loss: 1.0383\n",
            "Epoch 235/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 1.0498 - val_loss: 1.0347\n",
            "Epoch 236/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.0469 - val_loss: 1.0322\n",
            "Epoch 237/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 1.0455 - val_loss: 1.0281\n",
            "Epoch 238/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.0404 - val_loss: 1.0291\n",
            "Epoch 239/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 1.0389 - val_loss: 1.0247\n",
            "Epoch 240/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.0364 - val_loss: 1.0247\n",
            "Epoch 241/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 1.0321 - val_loss: 1.0222\n",
            "Epoch 242/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 1.0299 - val_loss: 1.0192\n",
            "Epoch 243/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.0277 - val_loss: 1.0143\n",
            "Epoch 244/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.0240 - val_loss: 1.0145\n",
            "Epoch 245/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.0212 - val_loss: 1.0166\n",
            "Epoch 246/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 1.0195 - val_loss: 1.0095\n",
            "Epoch 247/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.0151 - val_loss: 1.0089\n",
            "Epoch 248/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.0115 - val_loss: 1.0096\n",
            "Epoch 249/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 1.0111 - val_loss: 1.0028\n",
            "Epoch 250/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 1.0061 - val_loss: 1.0019\n",
            "Epoch 251/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 1.0049 - val_loss: 1.0032\n",
            "Epoch 252/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 1.0005 - val_loss: 0.9982\n",
            "Epoch 253/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 0.9978 - val_loss: 0.9932\n",
            "Epoch 254/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.9946 - val_loss: 0.9920\n",
            "Epoch 255/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 0.9931 - val_loss: 0.9908\n",
            "Epoch 256/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 0.9906 - val_loss: 0.9866\n",
            "Epoch 257/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.9873 - val_loss: 0.9844\n",
            "Epoch 258/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.9840 - val_loss: 0.9846\n",
            "Epoch 259/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.9807 - val_loss: 0.9814\n",
            "Epoch 260/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.9779 - val_loss: 0.9799\n",
            "Epoch 261/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.9753 - val_loss: 0.9773\n",
            "Epoch 262/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.9718 - val_loss: 0.9730\n",
            "Epoch 263/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.9697 - val_loss: 0.9705\n",
            "Epoch 264/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.9649 - val_loss: 0.9708\n",
            "Epoch 265/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 0.9644 - val_loss: 0.9676\n",
            "Epoch 266/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.9607 - val_loss: 0.9642\n",
            "Epoch 267/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 0.9580 - val_loss: 0.9623\n",
            "Epoch 268/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.9545 - val_loss: 0.9601\n",
            "Epoch 269/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.9514 - val_loss: 0.9603\n",
            "Epoch 270/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.9494 - val_loss: 0.9587\n",
            "Epoch 271/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.9460 - val_loss: 0.9558\n",
            "Epoch 272/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.9444 - val_loss: 0.9523\n",
            "Epoch 273/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.9403 - val_loss: 0.9518\n",
            "Epoch 274/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 0.9383 - val_loss: 0.9487\n",
            "Epoch 275/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 0.9358 - val_loss: 0.9473\n",
            "Epoch 276/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.9334 - val_loss: 0.9444\n",
            "Epoch 277/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 0.9305 - val_loss: 0.9429\n",
            "Epoch 278/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.9275 - val_loss: 0.9411\n",
            "Epoch 279/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.9257 - val_loss: 0.9393\n",
            "Epoch 280/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.9229 - val_loss: 0.9375\n",
            "Epoch 281/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.9203 - val_loss: 0.9364\n",
            "Epoch 282/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.9186 - val_loss: 0.9338\n",
            "Epoch 283/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 0.9159 - val_loss: 0.9327\n",
            "Epoch 284/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.9139 - val_loss: 0.9308\n",
            "Epoch 285/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.9118 - val_loss: 0.9298\n",
            "Epoch 286/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.9099 - val_loss: 0.9276\n",
            "Epoch 287/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 0.9079 - val_loss: 0.9268\n",
            "Epoch 288/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.9059 - val_loss: 0.9249\n",
            "Epoch 289/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 0.9037 - val_loss: 0.9229\n",
            "Epoch 290/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 0.9023 - val_loss: 0.9223\n",
            "Epoch 291/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.9007 - val_loss: 0.9205\n",
            "Epoch 292/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8988 - val_loss: 0.9195\n",
            "Epoch 293/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 0.8969 - val_loss: 0.9178\n",
            "Epoch 294/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8954 - val_loss: 0.9168\n",
            "Epoch 295/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8940 - val_loss: 0.9156\n",
            "Epoch 296/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 0.8924 - val_loss: 0.9141\n",
            "Epoch 297/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8910 - val_loss: 0.9134\n",
            "Epoch 298/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 0.8893 - val_loss: 0.9126\n",
            "Epoch 299/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 0.8878 - val_loss: 0.9117\n",
            "Epoch 300/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 0.8869 - val_loss: 0.9108\n",
            "Epoch 301/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 0.8856 - val_loss: 0.9099\n",
            "Epoch 302/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 0.8843 - val_loss: 0.9090\n",
            "Epoch 303/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 0.8832 - val_loss: 0.9083\n",
            "Epoch 304/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8821 - val_loss: 0.9070\n",
            "Epoch 305/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 0.8811 - val_loss: 0.9064\n",
            "Epoch 306/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8799 - val_loss: 0.9055\n",
            "Epoch 307/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8791 - val_loss: 0.9049\n",
            "Epoch 308/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8782 - val_loss: 0.9039\n",
            "Epoch 309/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 0.8773 - val_loss: 0.9034\n",
            "Epoch 310/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8763 - val_loss: 0.9025\n",
            "Epoch 311/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8757 - val_loss: 0.9022\n",
            "Epoch 312/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8749 - val_loss: 0.9015\n",
            "Epoch 313/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 0.8741 - val_loss: 0.9011\n",
            "Epoch 314/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 0.8734 - val_loss: 0.9002\n",
            "Epoch 315/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8725 - val_loss: 0.8996\n",
            "Epoch 316/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8719 - val_loss: 0.8994\n",
            "Epoch 317/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8713 - val_loss: 0.8985\n",
            "Epoch 318/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 0.8706 - val_loss: 0.8983\n",
            "Epoch 319/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8701 - val_loss: 0.8978\n",
            "Epoch 320/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8695 - val_loss: 0.8973\n",
            "Epoch 321/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8689 - val_loss: 0.8968\n",
            "Epoch 322/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8684 - val_loss: 0.8966\n",
            "Epoch 323/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8679 - val_loss: 0.8962\n",
            "Epoch 324/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8674 - val_loss: 0.8957\n",
            "Epoch 325/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8669 - val_loss: 0.8953\n",
            "Epoch 326/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 0.8665 - val_loss: 0.8952\n",
            "Epoch 327/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8660 - val_loss: 0.8948\n",
            "Epoch 328/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8656 - val_loss: 0.8945\n",
            "Epoch 329/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8652 - val_loss: 0.8940\n",
            "Epoch 330/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 0.8648 - val_loss: 0.8939\n",
            "Epoch 331/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8644 - val_loss: 0.8935\n",
            "Epoch 332/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8641 - val_loss: 0.8933\n",
            "Epoch 333/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8637 - val_loss: 0.8929\n",
            "Epoch 334/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8634 - val_loss: 0.8926\n",
            "Epoch 335/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 0.8630 - val_loss: 0.8925\n",
            "Epoch 336/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8627 - val_loss: 0.8923\n",
            "Epoch 337/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8624 - val_loss: 0.8919\n",
            "Epoch 338/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 0.8621 - val_loss: 0.8917\n",
            "Epoch 339/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 0.8618 - val_loss: 0.8916\n",
            "Epoch 340/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 0.8616 - val_loss: 0.8912\n",
            "Epoch 341/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8613 - val_loss: 0.8910\n",
            "Epoch 342/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8610 - val_loss: 0.8908\n",
            "Epoch 343/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8607 - val_loss: 0.8905\n",
            "Epoch 344/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 0.8605 - val_loss: 0.8904\n",
            "Epoch 345/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 0.8603 - val_loss: 0.8903\n",
            "Epoch 346/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8600 - val_loss: 0.8902\n",
            "Epoch 347/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8599 - val_loss: 0.8901\n",
            "Epoch 348/1000\n",
            "70/70 [==============================] - 1s 12ms/step - loss: 0.8598 - val_loss: 0.8898\n",
            "Epoch 349/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8595 - val_loss: 0.8896\n",
            "Epoch 350/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8593 - val_loss: 0.8896\n",
            "Epoch 351/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8591 - val_loss: 0.8893\n",
            "Epoch 352/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8589 - val_loss: 0.8892\n",
            "Epoch 353/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8587 - val_loss: 0.8890\n",
            "Epoch 354/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8585 - val_loss: 0.8889\n",
            "Epoch 355/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8584 - val_loss: 0.8887\n",
            "Epoch 356/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8582 - val_loss: 0.8887\n",
            "Epoch 357/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8580 - val_loss: 0.8884\n",
            "Epoch 358/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8579 - val_loss: 0.8884\n",
            "Epoch 359/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8577 - val_loss: 0.8883\n",
            "Epoch 360/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8576 - val_loss: 0.8881\n",
            "Epoch 361/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8574 - val_loss: 0.8880\n",
            "Epoch 362/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8573 - val_loss: 0.8879\n",
            "Epoch 363/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8571 - val_loss: 0.8877\n",
            "Epoch 364/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8570 - val_loss: 0.8877\n",
            "Epoch 365/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8568 - val_loss: 0.8875\n",
            "Epoch 366/1000\n",
            "70/70 [==============================] - 1s 18ms/step - loss: 0.8567 - val_loss: 0.8875\n",
            "Epoch 367/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8566 - val_loss: 0.8873\n",
            "Epoch 368/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8565 - val_loss: 0.8873\n",
            "Epoch 369/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8564 - val_loss: 0.8869\n",
            "Epoch 370/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8562 - val_loss: 0.8869\n",
            "Epoch 371/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8561 - val_loss: 0.8869\n",
            "Epoch 372/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8560 - val_loss: 0.8868\n",
            "Epoch 373/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8559 - val_loss: 0.8868\n",
            "Epoch 374/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8558 - val_loss: 0.8867\n",
            "Epoch 375/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8557 - val_loss: 0.8866\n",
            "Epoch 376/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8556 - val_loss: 0.8865\n",
            "Epoch 377/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8555 - val_loss: 0.8864\n",
            "Epoch 378/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8554 - val_loss: 0.8864\n",
            "Epoch 379/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8554 - val_loss: 0.8863\n",
            "Epoch 380/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8553 - val_loss: 0.8862\n",
            "Epoch 381/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8551 - val_loss: 0.8861\n",
            "Epoch 382/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8551 - val_loss: 0.8860\n",
            "Epoch 383/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8550 - val_loss: 0.8859\n",
            "Epoch 384/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8549 - val_loss: 0.8857\n",
            "Epoch 385/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8549 - val_loss: 0.8858\n",
            "Epoch 386/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8548 - val_loss: 0.8857\n",
            "Epoch 387/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8547 - val_loss: 0.8857\n",
            "Epoch 388/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8546 - val_loss: 0.8856\n",
            "Epoch 389/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8545 - val_loss: 0.8856\n",
            "Epoch 390/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8545 - val_loss: 0.8854\n",
            "Epoch 391/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8544 - val_loss: 0.8854\n",
            "Epoch 392/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8543 - val_loss: 0.8853\n",
            "Epoch 393/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8543 - val_loss: 0.8853\n",
            "Epoch 394/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8542 - val_loss: 0.8852\n",
            "Epoch 395/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8541 - val_loss: 0.8852\n",
            "Epoch 396/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8541 - val_loss: 0.8851\n",
            "Epoch 397/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8540 - val_loss: 0.8850\n",
            "Epoch 398/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8539 - val_loss: 0.8850\n",
            "Epoch 399/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8539 - val_loss: 0.8850\n",
            "Epoch 400/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8539 - val_loss: 0.8849\n",
            "Epoch 401/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8538 - val_loss: 0.8848\n",
            "Epoch 402/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8537 - val_loss: 0.8848\n",
            "Epoch 403/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8537 - val_loss: 0.8847\n",
            "Epoch 404/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8536 - val_loss: 0.8848\n",
            "Epoch 405/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8536 - val_loss: 0.8847\n",
            "Epoch 406/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8535 - val_loss: 0.8847\n",
            "Epoch 407/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8535 - val_loss: 0.8846\n",
            "Epoch 408/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8535 - val_loss: 0.8846\n",
            "Epoch 409/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8534 - val_loss: 0.8845\n",
            "Epoch 410/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8533 - val_loss: 0.8844\n",
            "Epoch 411/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8533 - val_loss: 0.8844\n",
            "Epoch 412/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8533 - val_loss: 0.8844\n",
            "Epoch 413/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8532 - val_loss: 0.8844\n",
            "Epoch 414/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8532 - val_loss: 0.8843\n",
            "Epoch 415/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8531 - val_loss: 0.8843\n",
            "Epoch 416/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8531 - val_loss: 0.8843\n",
            "Epoch 417/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8531 - val_loss: 0.8842\n",
            "Epoch 418/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8530 - val_loss: 0.8842\n",
            "Epoch 419/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8530 - val_loss: 0.8841\n",
            "Epoch 420/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8530 - val_loss: 0.8841\n",
            "Epoch 421/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8529 - val_loss: 0.8841\n",
            "Epoch 422/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8529 - val_loss: 0.8840\n",
            "Epoch 423/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8528 - val_loss: 0.8840\n",
            "Epoch 424/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8528 - val_loss: 0.8839\n",
            "Epoch 425/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8528 - val_loss: 0.8839\n",
            "Epoch 426/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8528 - val_loss: 0.8839\n",
            "Epoch 427/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8527 - val_loss: 0.8838\n",
            "Epoch 428/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8527 - val_loss: 0.8838\n",
            "Epoch 429/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8527 - val_loss: 0.8838\n",
            "Epoch 430/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8526 - val_loss: 0.8838\n",
            "Epoch 431/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8526 - val_loss: 0.8837\n",
            "Epoch 432/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8526 - val_loss: 0.8838\n",
            "Epoch 433/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8526 - val_loss: 0.8837\n",
            "Epoch 434/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8525 - val_loss: 0.8837\n",
            "Epoch 435/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8525 - val_loss: 0.8836\n",
            "Epoch 436/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8525 - val_loss: 0.8836\n",
            "Epoch 437/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8525 - val_loss: 0.8836\n",
            "Epoch 438/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8525 - val_loss: 0.8835\n",
            "Epoch 439/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8524 - val_loss: 0.8835\n",
            "Epoch 440/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8524 - val_loss: 0.8835\n",
            "Epoch 441/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8524 - val_loss: 0.8835\n",
            "Epoch 442/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8523 - val_loss: 0.8835\n",
            "Epoch 443/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8523 - val_loss: 0.8834\n",
            "Epoch 444/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8523 - val_loss: 0.8834\n",
            "Epoch 445/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8523 - val_loss: 0.8834\n",
            "Epoch 446/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8523 - val_loss: 0.8834\n",
            "Epoch 447/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8523 - val_loss: 0.8834\n",
            "Epoch 448/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8522 - val_loss: 0.8834\n",
            "Epoch 449/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8522 - val_loss: 0.8834\n",
            "Epoch 450/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8522 - val_loss: 0.8833\n",
            "Epoch 451/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8522 - val_loss: 0.8833\n",
            "Epoch 452/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8522 - val_loss: 0.8833\n",
            "Epoch 453/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8521 - val_loss: 0.8833\n",
            "Epoch 454/1000\n",
            "70/70 [==============================] - 1s 19ms/step - loss: 0.8521 - val_loss: 0.8833\n",
            "Epoch 455/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8521 - val_loss: 0.8833\n",
            "Epoch 456/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8521 - val_loss: 0.8832\n",
            "Epoch 457/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8521 - val_loss: 0.8832\n",
            "Epoch 458/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8520 - val_loss: 0.8832\n",
            "Epoch 459/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8520 - val_loss: 0.8832\n",
            "Epoch 460/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8520 - val_loss: 0.8831\n",
            "Epoch 461/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8520 - val_loss: 0.8831\n",
            "Epoch 462/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8520 - val_loss: 0.8831\n",
            "Epoch 463/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8520 - val_loss: 0.8831\n",
            "Epoch 464/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8520 - val_loss: 0.8831\n",
            "Epoch 465/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8520 - val_loss: 0.8831\n",
            "Epoch 466/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8520 - val_loss: 0.8830\n",
            "Epoch 467/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8519 - val_loss: 0.8830\n",
            "Epoch 468/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8519 - val_loss: 0.8830\n",
            "Epoch 469/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8519 - val_loss: 0.8830\n",
            "Epoch 470/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8519 - val_loss: 0.8830\n",
            "Epoch 471/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8519 - val_loss: 0.8829\n",
            "Epoch 472/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8519 - val_loss: 0.8829\n",
            "Epoch 473/1000\n",
            "70/70 [==============================] - 1s 18ms/step - loss: 0.8519 - val_loss: 0.8829\n",
            "Epoch 474/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8518 - val_loss: 0.8829\n",
            "Epoch 475/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8518 - val_loss: 0.8829\n",
            "Epoch 476/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8518 - val_loss: 0.8829\n",
            "Epoch 477/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8518 - val_loss: 0.8829\n",
            "Epoch 478/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8518 - val_loss: 0.8829\n",
            "Epoch 479/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8518 - val_loss: 0.8828\n",
            "Epoch 480/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8518 - val_loss: 0.8828\n",
            "Epoch 481/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8518 - val_loss: 0.8828\n",
            "Epoch 482/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8517 - val_loss: 0.8828\n",
            "Epoch 483/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8517 - val_loss: 0.8828\n",
            "Epoch 484/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8517 - val_loss: 0.8828\n",
            "Epoch 485/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8517 - val_loss: 0.8828\n",
            "Epoch 486/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8517 - val_loss: 0.8828\n",
            "Epoch 487/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8517 - val_loss: 0.8827\n",
            "Epoch 488/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8517 - val_loss: 0.8828\n",
            "Epoch 489/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8517 - val_loss: 0.8827\n",
            "Epoch 490/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8517 - val_loss: 0.8827\n",
            "Epoch 491/1000\n",
            "70/70 [==============================] - 1s 18ms/step - loss: 0.8517 - val_loss: 0.8827\n",
            "Epoch 492/1000\n",
            "70/70 [==============================] - 1s 15ms/step - loss: 0.8517 - val_loss: 0.8827\n",
            "Epoch 493/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8517 - val_loss: 0.8827\n",
            "Epoch 494/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8516 - val_loss: 0.8827\n",
            "Epoch 495/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8516 - val_loss: 0.8826\n",
            "Epoch 496/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8516 - val_loss: 0.8827\n",
            "Epoch 497/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8516 - val_loss: 0.8826\n",
            "Epoch 498/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8516 - val_loss: 0.8826\n",
            "Epoch 499/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8516 - val_loss: 0.8827\n",
            "Epoch 500/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8516 - val_loss: 0.8826\n",
            "Epoch 501/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8516 - val_loss: 0.8826\n",
            "Epoch 502/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8516 - val_loss: 0.8826\n",
            "Epoch 503/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8516 - val_loss: 0.8826\n",
            "Epoch 504/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8516 - val_loss: 0.8826\n",
            "Epoch 505/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8516 - val_loss: 0.8826\n",
            "Epoch 506/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8516 - val_loss: 0.8826\n",
            "Epoch 507/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8515 - val_loss: 0.8826\n",
            "Epoch 508/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8516 - val_loss: 0.8826\n",
            "Epoch 509/1000\n",
            "70/70 [==============================] - 1s 15ms/step - loss: 0.8515 - val_loss: 0.8826\n",
            "Epoch 510/1000\n",
            "70/70 [==============================] - 1s 15ms/step - loss: 0.8515 - val_loss: 0.8826\n",
            "Epoch 511/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8516 - val_loss: 0.8825\n",
            "Epoch 512/1000\n",
            "70/70 [==============================] - 1s 15ms/step - loss: 0.8515 - val_loss: 0.8826\n",
            "Epoch 513/1000\n",
            "70/70 [==============================] - 1s 15ms/step - loss: 0.8515 - val_loss: 0.8826\n",
            "Epoch 514/1000\n",
            "70/70 [==============================] - 1s 15ms/step - loss: 0.8515 - val_loss: 0.8826\n",
            "Epoch 515/1000\n",
            "70/70 [==============================] - 1s 15ms/step - loss: 0.8515 - val_loss: 0.8825\n",
            "Epoch 516/1000\n",
            "70/70 [==============================] - 1s 15ms/step - loss: 0.8515 - val_loss: 0.8825\n",
            "Epoch 517/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8515 - val_loss: 0.8825\n",
            "Epoch 518/1000\n",
            "70/70 [==============================] - 1s 15ms/step - loss: 0.8515 - val_loss: 0.8825\n",
            "Epoch 519/1000\n",
            "70/70 [==============================] - 1s 15ms/step - loss: 0.8515 - val_loss: 0.8825\n",
            "Epoch 520/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8515 - val_loss: 0.8825\n",
            "Epoch 521/1000\n",
            "70/70 [==============================] - 1s 19ms/step - loss: 0.8515 - val_loss: 0.8825\n",
            "Epoch 522/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8515 - val_loss: 0.8825\n",
            "Epoch 523/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8515 - val_loss: 0.8825\n",
            "Epoch 524/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8515 - val_loss: 0.8825\n",
            "Epoch 525/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8515 - val_loss: 0.8825\n",
            "Epoch 526/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8515 - val_loss: 0.8825\n",
            "Epoch 527/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8515 - val_loss: 0.8825\n",
            "Epoch 528/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8515 - val_loss: 0.8825\n",
            "Epoch 529/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8515 - val_loss: 0.8825\n",
            "Epoch 530/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8514 - val_loss: 0.8825\n",
            "Epoch 531/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8514 - val_loss: 0.8825\n",
            "Epoch 532/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8514 - val_loss: 0.8824\n",
            "Epoch 533/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8514 - val_loss: 0.8825\n",
            "Epoch 534/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8514 - val_loss: 0.8824\n",
            "Epoch 535/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8514 - val_loss: 0.8824\n",
            "Epoch 536/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8514 - val_loss: 0.8825\n",
            "Epoch 537/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8514 - val_loss: 0.8824\n",
            "Epoch 538/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8514 - val_loss: 0.8824\n",
            "Epoch 539/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8514 - val_loss: 0.8824\n",
            "Epoch 540/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8514 - val_loss: 0.8824\n",
            "Epoch 541/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8514 - val_loss: 0.8825\n",
            "Epoch 542/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8514 - val_loss: 0.8825\n",
            "Epoch 543/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8514 - val_loss: 0.8824\n",
            "Epoch 544/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8514 - val_loss: 0.8824\n",
            "Epoch 545/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8514 - val_loss: 0.8824\n",
            "Epoch 546/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8514 - val_loss: 0.8824\n",
            "Epoch 547/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8514 - val_loss: 0.8824\n",
            "Epoch 548/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8514 - val_loss: 0.8824\n",
            "Epoch 549/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8514 - val_loss: 0.8824\n",
            "Epoch 550/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8514 - val_loss: 0.8824\n",
            "Epoch 551/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8514 - val_loss: 0.8824\n",
            "Epoch 552/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8514 - val_loss: 0.8824\n",
            "Epoch 553/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8514 - val_loss: 0.8824\n",
            "Epoch 554/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8514 - val_loss: 0.8824\n",
            "Epoch 555/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8514 - val_loss: 0.8824\n",
            "Epoch 556/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8514 - val_loss: 0.8824\n",
            "Epoch 557/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8514 - val_loss: 0.8824\n",
            "Epoch 558/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8514 - val_loss: 0.8824\n",
            "Epoch 559/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8514 - val_loss: 0.8823\n",
            "Epoch 560/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8514 - val_loss: 0.8824\n",
            "Epoch 561/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8514 - val_loss: 0.8823\n",
            "Epoch 562/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8514 - val_loss: 0.8824\n",
            "Epoch 563/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8513 - val_loss: 0.8823\n",
            "Epoch 564/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8513 - val_loss: 0.8823\n",
            "Epoch 565/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8513 - val_loss: 0.8823\n",
            "Epoch 566/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8513 - val_loss: 0.8823\n",
            "Epoch 567/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8513 - val_loss: 0.8823\n",
            "Epoch 568/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8513 - val_loss: 0.8823\n",
            "Epoch 569/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8513 - val_loss: 0.8823\n",
            "Epoch 570/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8513 - val_loss: 0.8823\n",
            "Epoch 571/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8513 - val_loss: 0.8823\n",
            "Epoch 572/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8513 - val_loss: 0.8823\n",
            "Epoch 573/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8513 - val_loss: 0.8823\n",
            "Epoch 574/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8513 - val_loss: 0.8823\n",
            "Epoch 575/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8513 - val_loss: 0.8823\n",
            "Epoch 576/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8513 - val_loss: 0.8823\n",
            "Epoch 577/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8513 - val_loss: 0.8823\n",
            "Epoch 578/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8513 - val_loss: 0.8823\n",
            "Epoch 579/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8513 - val_loss: 0.8823\n",
            "Epoch 580/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8513 - val_loss: 0.8823\n",
            "Epoch 581/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8513 - val_loss: 0.8823\n",
            "Epoch 582/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8513 - val_loss: 0.8822\n",
            "Epoch 583/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8513 - val_loss: 0.8822\n",
            "Epoch 584/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8513 - val_loss: 0.8822\n",
            "Epoch 585/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8513 - val_loss: 0.8823\n",
            "Epoch 586/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8513 - val_loss: 0.8822\n",
            "Epoch 587/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8513 - val_loss: 0.8822\n",
            "Epoch 588/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8513 - val_loss: 0.8822\n",
            "Epoch 589/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8513 - val_loss: 0.8822\n",
            "Epoch 590/1000\n",
            "70/70 [==============================] - 1s 18ms/step - loss: 0.8513 - val_loss: 0.8822\n",
            "Epoch 591/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8513 - val_loss: 0.8822\n",
            "Epoch 592/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8513 - val_loss: 0.8823\n",
            "Epoch 593/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8513 - val_loss: 0.8822\n",
            "Epoch 594/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8513 - val_loss: 0.8822\n",
            "Epoch 595/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8513 - val_loss: 0.8822\n",
            "Epoch 596/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8513 - val_loss: 0.8822\n",
            "Epoch 597/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8513 - val_loss: 0.8822\n",
            "Epoch 598/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8513 - val_loss: 0.8822\n",
            "Epoch 599/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8513 - val_loss: 0.8822\n",
            "Epoch 600/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8513 - val_loss: 0.8822\n",
            "Epoch 601/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8513 - val_loss: 0.8822\n",
            "Epoch 602/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8513 - val_loss: 0.8822\n",
            "Epoch 603/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8513 - val_loss: 0.8822\n",
            "Epoch 604/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8513 - val_loss: 0.8822\n",
            "Epoch 605/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8513 - val_loss: 0.8822\n",
            "Epoch 606/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8513 - val_loss: 0.8822\n",
            "Epoch 607/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8513 - val_loss: 0.8822\n",
            "Epoch 608/1000\n",
            "70/70 [==============================] - 1s 15ms/step - loss: 0.8513 - val_loss: 0.8822\n",
            "Epoch 609/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8513 - val_loss: 0.8822\n",
            "Epoch 610/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8513 - val_loss: 0.8822\n",
            "Epoch 611/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8513 - val_loss: 0.8822\n",
            "Epoch 612/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8513 - val_loss: 0.8822\n",
            "Epoch 613/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8513 - val_loss: 0.8822\n",
            "Epoch 614/1000\n",
            "70/70 [==============================] - 1s 17ms/step - loss: 0.8513 - val_loss: 0.8822\n",
            "Epoch 615/1000\n",
            "70/70 [==============================] - 1s 17ms/step - loss: 0.8513 - val_loss: 0.8822\n",
            "Epoch 616/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8513 - val_loss: 0.8822\n",
            "Epoch 617/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8512 - val_loss: 0.8821\n",
            "Epoch 618/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8513 - val_loss: 0.8822\n",
            "Epoch 619/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8513 - val_loss: 0.8822\n",
            "Epoch 620/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8513 - val_loss: 0.8821\n",
            "Epoch 621/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8513 - val_loss: 0.8821\n",
            "Epoch 622/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8821\n",
            "Epoch 623/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8513 - val_loss: 0.8821\n",
            "Epoch 624/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8821\n",
            "Epoch 625/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8822\n",
            "Epoch 626/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8821\n",
            "Epoch 627/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8513 - val_loss: 0.8821\n",
            "Epoch 628/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8512 - val_loss: 0.8821\n",
            "Epoch 629/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8821\n",
            "Epoch 630/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8512 - val_loss: 0.8821\n",
            "Epoch 631/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8821\n",
            "Epoch 632/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8821\n",
            "Epoch 633/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8821\n",
            "Epoch 634/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8821\n",
            "Epoch 635/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8512 - val_loss: 0.8821\n",
            "Epoch 636/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8512 - val_loss: 0.8821\n",
            "Epoch 637/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8512 - val_loss: 0.8821\n",
            "Epoch 638/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8821\n",
            "Epoch 639/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8821\n",
            "Epoch 640/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8821\n",
            "Epoch 641/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8821\n",
            "Epoch 642/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8821\n",
            "Epoch 643/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8821\n",
            "Epoch 644/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8821\n",
            "Epoch 645/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8821\n",
            "Epoch 646/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8821\n",
            "Epoch 647/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8512 - val_loss: 0.8821\n",
            "Epoch 648/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8512 - val_loss: 0.8821\n",
            "Epoch 649/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8821\n",
            "Epoch 650/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8821\n",
            "Epoch 651/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8821\n",
            "Epoch 652/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8821\n",
            "Epoch 653/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8821\n",
            "Epoch 654/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8821\n",
            "Epoch 655/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8821\n",
            "Epoch 656/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8821\n",
            "Epoch 657/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8821\n",
            "Epoch 658/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8512 - val_loss: 0.8821\n",
            "Epoch 659/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8512 - val_loss: 0.8821\n",
            "Epoch 660/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8821\n",
            "Epoch 661/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8512 - val_loss: 0.8821\n",
            "Epoch 662/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8821\n",
            "Epoch 663/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8821\n",
            "Epoch 664/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8821\n",
            "Epoch 665/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8821\n",
            "Epoch 666/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8821\n",
            "Epoch 667/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8512 - val_loss: 0.8820\n",
            "Epoch 668/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8821\n",
            "Epoch 669/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8512 - val_loss: 0.8820\n",
            "Epoch 670/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8512 - val_loss: 0.8820\n",
            "Epoch 671/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8821\n",
            "Epoch 672/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8820\n",
            "Epoch 673/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8820\n",
            "Epoch 674/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8820\n",
            "Epoch 675/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8820\n",
            "Epoch 676/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8821\n",
            "Epoch 677/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8820\n",
            "Epoch 678/1000\n",
            "70/70 [==============================] - 1s 15ms/step - loss: 0.8512 - val_loss: 0.8821\n",
            "Epoch 679/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8820\n",
            "Epoch 680/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8820\n",
            "Epoch 681/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8820\n",
            "Epoch 682/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8820\n",
            "Epoch 683/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8820\n",
            "Epoch 684/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8512 - val_loss: 0.8821\n",
            "Epoch 685/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8820\n",
            "Epoch 686/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8512 - val_loss: 0.8820\n",
            "Epoch 687/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8820\n",
            "Epoch 688/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8821\n",
            "Epoch 689/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8820\n",
            "Epoch 690/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8821\n",
            "Epoch 691/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8820\n",
            "Epoch 692/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8820\n",
            "Epoch 693/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8820\n",
            "Epoch 694/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8820\n",
            "Epoch 695/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8821\n",
            "Epoch 696/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8820\n",
            "Epoch 697/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8820\n",
            "Epoch 698/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8820\n",
            "Epoch 699/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8512 - val_loss: 0.8820\n",
            "Epoch 700/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8820\n",
            "Epoch 701/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8820\n",
            "Epoch 702/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8820\n",
            "Epoch 703/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8820\n",
            "Epoch 704/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8512 - val_loss: 0.8820\n",
            "Epoch 705/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8820\n",
            "Epoch 706/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8820\n",
            "Epoch 707/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8820\n",
            "Epoch 708/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8820\n",
            "Epoch 709/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8820\n",
            "Epoch 710/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8820\n",
            "Epoch 711/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8820\n",
            "Epoch 712/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8820\n",
            "Epoch 713/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8512 - val_loss: 0.8820\n",
            "Epoch 714/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8820\n",
            "Epoch 715/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8820\n",
            "Epoch 716/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8820\n",
            "Epoch 717/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8820\n",
            "Epoch 718/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8820\n",
            "Epoch 719/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8820\n",
            "Epoch 720/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8820\n",
            "Epoch 721/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8820\n",
            "Epoch 722/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8820\n",
            "Epoch 723/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8820\n",
            "Epoch 724/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8820\n",
            "Epoch 725/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8820\n",
            "Epoch 726/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8819\n",
            "Epoch 727/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8820\n",
            "Epoch 728/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8819\n",
            "Epoch 729/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8820\n",
            "Epoch 730/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8512 - val_loss: 0.8820\n",
            "Epoch 731/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8820\n",
            "Epoch 732/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8820\n",
            "Epoch 733/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8820\n",
            "Epoch 734/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8819\n",
            "Epoch 735/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8820\n",
            "Epoch 736/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8819\n",
            "Epoch 737/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8819\n",
            "Epoch 738/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8820\n",
            "Epoch 739/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8819\n",
            "Epoch 740/1000\n",
            "70/70 [==============================] - 1s 19ms/step - loss: 0.8512 - val_loss: 0.8820\n",
            "Epoch 741/1000\n",
            "70/70 [==============================] - 1s 16ms/step - loss: 0.8512 - val_loss: 0.8819\n",
            "Epoch 742/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8820\n",
            "Epoch 743/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8819\n",
            "Epoch 744/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8819\n",
            "Epoch 745/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8512 - val_loss: 0.8820\n",
            "Epoch 746/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8820\n",
            "Epoch 747/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8820\n",
            "Epoch 748/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8820\n",
            "Epoch 749/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8820\n",
            "Epoch 750/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8820\n",
            "Epoch 751/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8819\n",
            "Epoch 752/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8819\n",
            "Epoch 753/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8819\n",
            "Epoch 754/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8819\n",
            "Epoch 755/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8820\n",
            "Epoch 756/1000\n",
            "70/70 [==============================] - 1s 18ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 757/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8819\n",
            "Epoch 758/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 759/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8820\n",
            "Epoch 760/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8819\n",
            "Epoch 761/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 762/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8819\n",
            "Epoch 763/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8820\n",
            "Epoch 764/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8512 - val_loss: 0.8819\n",
            "Epoch 765/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 766/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8512 - val_loss: 0.8819\n",
            "Epoch 767/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 768/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 769/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 770/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8820\n",
            "Epoch 771/1000\n",
            "70/70 [==============================] - 1s 18ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 772/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 773/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 774/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 775/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8820\n",
            "Epoch 776/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 777/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8819\n",
            "Epoch 778/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 779/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 780/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 781/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 782/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 783/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 784/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8512 - val_loss: 0.8820\n",
            "Epoch 785/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 786/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 787/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8820\n",
            "Epoch 788/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 789/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8820\n",
            "Epoch 790/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 791/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 792/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 793/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 794/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 795/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 796/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 797/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 798/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 799/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 800/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 801/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 802/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 803/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 804/1000\n",
            "70/70 [==============================] - 1s 19ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 805/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 806/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 807/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 808/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 809/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 810/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 811/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 812/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 813/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 814/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 815/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 816/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 817/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 818/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 819/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 820/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 821/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 822/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 823/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 824/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 825/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 826/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 827/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 828/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 829/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 830/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 831/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 832/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8818\n",
            "Epoch 833/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 834/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 835/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 836/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 837/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 838/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 839/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 840/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 841/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 842/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 843/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 844/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 845/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 846/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 847/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 848/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 849/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 850/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 851/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 852/1000\n",
            "70/70 [==============================] - 1s 15ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 853/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 854/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 855/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 856/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 857/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 858/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 859/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 860/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 861/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 862/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 863/1000\n",
            "70/70 [==============================] - 1s 17ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 864/1000\n",
            "70/70 [==============================] - 1s 17ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 865/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 866/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 867/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 868/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 869/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 870/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8818\n",
            "Epoch 871/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8818\n",
            "Epoch 872/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8818\n",
            "Epoch 873/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8818\n",
            "Epoch 874/1000\n",
            "70/70 [==============================] - 1s 15ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 875/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8818\n",
            "Epoch 876/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8818\n",
            "Epoch 877/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8818\n",
            "Epoch 878/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8818\n",
            "Epoch 879/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8818\n",
            "Epoch 880/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8818\n",
            "Epoch 881/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8511 - val_loss: 0.8818\n",
            "Epoch 882/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8818\n",
            "Epoch 883/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8818\n",
            "Epoch 884/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8818\n",
            "Epoch 885/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8818\n",
            "Epoch 886/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8818\n",
            "Epoch 887/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 888/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8818\n",
            "Epoch 889/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 890/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8511 - val_loss: 0.8818\n",
            "Epoch 891/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8818\n",
            "Epoch 892/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8818\n",
            "Epoch 893/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8818\n",
            "Epoch 894/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 895/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 896/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8818\n",
            "Epoch 897/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 898/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 899/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8818\n",
            "Epoch 900/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 901/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 902/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 903/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8818\n",
            "Epoch 904/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 905/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8818\n",
            "Epoch 906/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 907/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 908/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8511 - val_loss: 0.8818\n",
            "Epoch 909/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 910/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 911/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 912/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 913/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 914/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 915/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 916/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 917/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 918/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 919/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 920/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 921/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 922/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 923/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 924/1000\n",
            "70/70 [==============================] - 1s 15ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 925/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 926/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 927/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 928/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 929/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 930/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 931/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 932/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 933/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 934/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8818\n",
            "Epoch 935/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8818\n",
            "Epoch 936/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 937/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8818\n",
            "Epoch 938/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 939/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 940/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8511 - val_loss: 0.8818\n",
            "Epoch 941/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 942/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 943/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 944/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 945/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 946/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 947/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 948/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 949/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 950/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 951/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8818\n",
            "Epoch 952/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 953/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 954/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8818\n",
            "Epoch 955/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8818\n",
            "Epoch 956/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8818\n",
            "Epoch 957/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 958/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8818\n",
            "Epoch 959/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8818\n",
            "Epoch 960/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8818\n",
            "Epoch 961/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8818\n",
            "Epoch 962/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8818\n",
            "Epoch 963/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8818\n",
            "Epoch 964/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8818\n",
            "Epoch 965/1000\n",
            "70/70 [==============================] - 1s 13ms/step - loss: 0.8511 - val_loss: 0.8818\n",
            "Epoch 966/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8818\n",
            "Epoch 967/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8818\n",
            "Epoch 968/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8818\n",
            "Epoch 969/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8818\n",
            "Epoch 970/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8818\n",
            "Epoch 971/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8818\n",
            "Epoch 972/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8818\n",
            "Epoch 973/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8818\n",
            "Epoch 974/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8818\n",
            "Epoch 975/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8818\n",
            "Epoch 976/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8818\n",
            "Epoch 977/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8818\n",
            "Epoch 978/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8818\n",
            "Epoch 979/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8818\n",
            "Epoch 980/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8818\n",
            "Epoch 981/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8818\n",
            "Epoch 982/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8818\n",
            "Epoch 983/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8818\n",
            "Epoch 984/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8818\n",
            "Epoch 985/1000\n",
            "70/70 [==============================] - 1s 17ms/step - loss: 0.8511 - val_loss: 0.8818\n",
            "Epoch 986/1000\n",
            "70/70 [==============================] - 1s 18ms/step - loss: 0.8511 - val_loss: 0.8818\n",
            "Epoch 987/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8818\n",
            "Epoch 988/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8818\n",
            "Epoch 989/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8818\n",
            "Epoch 990/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8818\n",
            "Epoch 991/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8818\n",
            "Epoch 992/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8819\n",
            "Epoch 993/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8818\n",
            "Epoch 994/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8818\n",
            "Epoch 995/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8818\n",
            "Epoch 996/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8818\n",
            "Epoch 997/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8818\n",
            "Epoch 998/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8818\n",
            "Epoch 999/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8818\n",
            "Epoch 1000/1000\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.8511 - val_loss: 0.8818\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    x_train_autorec,\n",
        "    x_train_autorec,\n",
        "    batch_size=128, # tama√±o del entrenamiento por lotes\n",
        "    epochs=1000,\n",
        "    verbose=1,\n",
        "    validation_data=(x_test_autorec, x_test_autorec))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "boVmfRvA6c0-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "c3139fda-64fb-40d3-e581-635fd7647952"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Plot p√©rdida de entrenamiento\n",
        "\n",
        "plt.plot(history.history[\"loss\"])\n",
        "plt.plot(history.history[\"val_loss\"], '--')\n",
        "plt.title(\"model loss\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.legend([\"train\", \"test\"], loc=\"upper left\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Evaluaci√≥n Recall@K**"
      ],
      "metadata": {
        "id": "9kQwyExkdIvc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "# un dict que almacena una lista de pares de valoraciones previstas y reales para cada usuario\n",
        "user_est_true = defaultdict(list)\n",
        "\n",
        "# iterar a trav√©s de los datos de validaci√≥n para construir el usuario-> [(y1, y1_hat), (y2, y2_hat)...]\n",
        "with torch.no_grad():\n",
        "    for i, batched_data in enumerate(x_test_autorec):\n",
        "        books = batched_data['books']\n",
        "        users = batched_data['users']\n",
        "        ratings = batched_data['ratings']\n",
        "\n",
        "        model_output = model(batched_data['books'], batched_data[\"users\"])\n",
        "\n",
        "        for i in range(len(users)):\n",
        "            book_id = books[i].item()\n",
        "            user_id = users[i].item()\n",
        "            pred_rating = model_output[i][0].item()\n",
        "            true_rating = ratings[i].item()\n",
        "\n",
        "            print(f\"{book_id}, {user_id}, {pred_rating}, {true_rating}\")\n",
        "            user_est_true[user_id].append((pred_rating, true_rating))\n"
      ],
      "metadata": {
        "id": "0-32yZPBeGGa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "4f047d5b-2809-4522-f03f-4907dc0ae002"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-a35ec51f997e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatched_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_autorec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mbooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatched_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'books'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0musers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatched_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'users'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mratings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatched_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ratings'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **RECOMENDACION AUTOENCODER**"
      ],
      "metadata": {
        "id": "AL4__Z-XcYm4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aWK29bTo6k9-"
      },
      "outputs": [],
      "source": [
        "def recommend_autorec(user_id, train, test, df_items, df_aux, num_items):\n",
        "  movies_watched_by_user = train[train.user == user_id]\n",
        "\n",
        "  df_items_aux = df_items[['item']]\n",
        "  df_items_aux['user'] = user_id\n",
        "  movies_not_watched = pd.merge(df_items_aux, movies_watched_by_user, on=['user', 'item'], how='left')\n",
        "  movies_not_watched = movies_not_watched[movies_not_watched.rating.isnull()][['user', 'item']]\n",
        "\n",
        "  df_input = movies_watched_by_user.groupby('user').agg({'item': list, 'rating': list}).reset_index()\n",
        "  df_input['input'] = df_input.apply(lambda x: np.squeeze(coo_matrix((x[2], (np.zeros_like(x[1]), x[1])),\n",
        "                                                          shape=(1, num_items)).toarray()),\n",
        "                                     axis=1)\n",
        "\n",
        "  x = np.stack(df_input.values[:, -1]).astype(float)\n",
        "  ratings = model.predict(x).flatten()\n",
        "  ratings_items = pd.DataFrame({'item': np.arange(num_items), 'predicted_rating': ratings})\n",
        "  ratings_items = pd.merge(ratings_items, movies_not_watched, on=['item'], how='left')\n",
        "  top_ratings_items = ratings_items[ratings_items.user.notnull()] \\\n",
        "    .sort_values(by='predicted_rating', ascending=False)[['item', 'predicted_rating']]\n",
        "\n",
        "  print(\"Mostrar recomendaciones para el usuario: {}\".format(user_id))\n",
        "  print(\"====\" * 9)\n",
        "  print(\"Pel√≠culas con altas valoraciones de los usuarios\")\n",
        "  print(\"----\" * 8)\n",
        "\n",
        "  movies_watched_by_user = pd.merge(movies_watched_by_user, df_aux, on=['item_id'])\n",
        "  top_movies_user = movies_watched_by_user.sort_values(by='rating', ascending=False)[['user', 'item', 'rating', 'movie_title']]\n",
        "  print(top_movies_user.head(20))\n",
        "\n",
        "  print(\"====\" * 9)\n",
        "  print(\"Calificaciones de las pel√≠culas vistas en los datos de prueba\")\n",
        "  print(\"----\" * 8)\n",
        "  movies_watched_by_user_test = test[test.user == user_id]\n",
        "  movies_watched_by_user_test = pd.merge(movies_watched_by_user_test, df_aux, on=['item_id'])\n",
        "  movies_watched_by_user_test = pd.merge(movies_watched_by_user_test, ratings_items, on=['user', 'item'])\n",
        "  movies_user_test = movies_watched_by_user_test.sort_values(by='rating', ascending=False)[['user', 'item', 'rating', 'predicted_rating', 'movie_title']]\n",
        "  print(movies_user_test.head(20))\n",
        "\n",
        "  print(\"----\" * 8)\n",
        "  print(\"Top 10 recomendaciones de pel√≠culas\")\n",
        "  print(\"----\" * 8)\n",
        "  top_movies_recommended = pd.merge(top_ratings_items, df_items, on=['item'])\n",
        "  top_movies_recommended = pd.merge(top_movies_recommended, df_aux, on=['item_id'])\n",
        "  print(top_movies_recommended[['item', 'predicted_rating', 'movie_title']].head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sqT7xnPl6mx8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "43007b6a-3100-4384-94e2-a34644f22d34"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-08bee66a9a69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0muser_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mrecommend_autorec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_item_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'df_item_info' is not defined"
          ]
        }
      ],
      "source": [
        "#Mostrar las 10 mejores recomendaciones de pel√≠culas a un usuario\n",
        "\n",
        "user_id = test.user.sample(1).iloc[0]\n",
        "recommend_autorec(user_id, train, test, df_items, df_item_info, num_items)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "lFAncW9-bez5",
        "9kQwyExkdIvc"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}